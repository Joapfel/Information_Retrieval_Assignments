{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from math import log10\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Pandas library to work with the data. In the cell below, we populate `COLUMN_LABELS` with the relevant columns and then import the training and test data sets. Then we print the first five elements to visualize the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_LABELS = ['Game Name', 'Class', 'Title', 'Review Text']\n",
    "train = pd.read_csv('games-train.csv', sep='\\t', names=COLUMN_LABELS)\n",
    "test = pd.read_csv('games-test.csv', sep='\\t', names=COLUMN_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hay Day</td>\n",
       "      <td>gut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spaß pur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bike Race Free</td>\n",
       "      <td>gut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Top game mit sucht Potenzial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subway Surfers</td>\n",
       "      <td>gut</td>\n",
       "      <td>Gut</td>\n",
       "      <td>Es lagt manchmal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subway Surfers</td>\n",
       "      <td>gut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Es ist ein tolles Spiel aber manchmal bleibt e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hay Day</td>\n",
       "      <td>gut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cccccccccooooooooooooooooo ooooooooooll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Game Name Class Title  \\\n",
       "0         Hay Day   gut   NaN   \n",
       "1  Bike Race Free   gut   NaN   \n",
       "2  Subway Surfers   gut   Gut   \n",
       "3  Subway Surfers   gut   NaN   \n",
       "4         Hay Day   gut   NaN   \n",
       "\n",
       "                                         Review Text  \n",
       "0                                           Spaß pur  \n",
       "1                       Top game mit sucht Potenzial  \n",
       "2                                   Es lagt manchmal  \n",
       "3  Es ist ein tolles Spiel aber manchmal bleibt e...  \n",
       "4            Cccccccccooooooooooooooooo ooooooooooll  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Farmville 2</td>\n",
       "      <td>schlecht</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echt schlecht , immer wen ich versuche zu star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Die Simpsons</td>\n",
       "      <td>gut</td>\n",
       "      <td>Buchi0202136</td>\n",
       "      <td>Suche noch freunde zum hinzufuegen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die Simpsons</td>\n",
       "      <td>gut</td>\n",
       "      <td>Suchtgefähr :) !!</td>\n",
       "      <td>Ich find das Spiel gut,man muss nicht permanen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die Simpsons</td>\n",
       "      <td>gut</td>\n",
       "      <td>Dauerhafter Spaß...</td>\n",
       "      <td>... durch immer neue Events. Schon 1 1/2 Jahre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subway Surfers</td>\n",
       "      <td>gut</td>\n",
       "      <td>Great</td>\n",
       "      <td>I like the game but near the last update it st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Game Name     Class                Title  \\\n",
       "0     Farmville 2  schlecht                  NaN   \n",
       "1    Die Simpsons       gut         Buchi0202136   \n",
       "2    Die Simpsons       gut    Suchtgefähr :) !!   \n",
       "3    Die Simpsons       gut  Dauerhafter Spaß...   \n",
       "4  Subway Surfers       gut                Great   \n",
       "\n",
       "                                         Review Text  \n",
       "0  Echt schlecht , immer wen ich versuche zu star...  \n",
       "1                 Suche noch freunde zum hinzufuegen  \n",
       "2  Ich find das Spiel gut,man muss nicht permanen...  \n",
       "3  ... durch immer neue Events. Schon 1 1/2 Jahre...  \n",
       "4  I like the game but near the last update it st...  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "We define a global `tokenize` method here so that we don't need to instantiate a new `TweetTokenizer` object every time we call the `preprocess` method. We use `TweetTokenizer` because the nature of online game reviews is not so different from that of tweets. Additionally, the `TweetTokenizer` has a length shortening parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = TweetTokenizer(reduce_len=True).tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    doc = str(doc).lower() # str() in case Pandas imported number as int type\n",
    "    doc = doc.translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "    return [token for token in tokenize(doc) if token not in stopwords.words('german')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_parameters(docs, collection_size): # docs = docs belonging to one class\n",
    "    p_y = len(docs) / collection_size\n",
    "    count = Counter()\n",
    "    for doc in docs:\n",
    "        count.update(preprocess(doc))\n",
    "        \n",
    "    return (p_y, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's estimate the parameters for each class in the data sets. We use Python's dict comprehension to map every unique value in the training data's class column (in this case just 'gut', 'schlecht') to the result of running `estimate_parameters` on a data set containing only elements of that class. For added clarity, we enumerate the variables below.\n",
    "\n",
    "- `params` = a dictionary of class to frequency distribution of terms in class\n",
    "- `class_` = a string containing either \"gut\" or \"schlecht\"\n",
    "- `train` = the training data as a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    class_: estimate_parameters(\n",
    "        train[train['Class'] == class_]['Review Text'], # Gets only the text of the review\n",
    "        len(train)\n",
    "    ) for class_ in train['Class'].unique() # = ['gut', 'schlecht']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p_y` for each class, or the distribution of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8230904656534169 0.1769095343465831\n"
     ]
    }
   ],
   "source": [
    "print(params['gut'][0], params['schlecht'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common words in the \"gut\" frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spiel', 33871),\n",
       " ('cool', 16236),\n",
       " ('macht', 13632),\n",
       " ('super', 11447),\n",
       " ('geil', 9955),\n",
       " ('gut', 9503),\n",
       " ('einfach', 8996),\n",
       " ('spaß', 8329),\n",
       " ('echt', 5912),\n",
       " ('immer', 4793)]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['gut'][1].most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 most common words in the \"schlecht\" frequency distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spiel', 9424),\n",
       " ('mehr', 6483),\n",
       " ('seit', 3275),\n",
       " ('bitte', 3263),\n",
       " ('immer', 3176),\n",
       " ('update', 3092),\n",
       " ('mal', 2639),\n",
       " ('geht', 2309),\n",
       " ('beheben', 2143),\n",
       " ('schon', 1973)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad[1].most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model to Predict Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by using the `predict` method on some easy examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gut', 3.763923847279274)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('tolles Spiel', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('schlecht', 16.50217592654949)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('das Spiel stürtzt immer ab. bitte schnell beheben', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On both examples, it acted just as we would expect. Now let's move on to the test data set. Let's assign `result` to a `Series` equal to the the prediction of each row in the \"Review Text\" column of `test`, then print the first five results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 34s, sys: 14.8 s, total: 4min 49s\n",
      "Wall time: 4min 50s\n"
     ]
    }
   ],
   "source": [
    "%time result = test['Review Text'].apply(lambda x: predict(x, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (schlecht, 24.71177312969205)\n",
       "1    (schlecht, 7.229119758952452)\n",
       "2    (schlecht, 71.83599943884803)\n",
       "3    (schlecht, 39.38009345437814)\n",
       "4         (gut, 45.68513157370194)\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract only the predictions and store it as `pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [x[0] for x in list(result)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize what this looks like, we'll create a `DataFrame` of the two sequences of predicted and true values, then print the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>schlecht</td>\n",
       "      <td>schlecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gut</td>\n",
       "      <td>schlecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gut</td>\n",
       "      <td>schlecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gut</td>\n",
       "      <td>schlecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gut</td>\n",
       "      <td>gut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       True Predicted\n",
       "0  schlecht  schlecht\n",
       "1       gut  schlecht\n",
       "2       gut  schlecht\n",
       "3       gut  schlecht\n",
       "4       gut       gut"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = pd.concat([test['Class'], pd.Series(pred)], axis=1)\n",
    "joined.columns = ['True', 'Predicted']\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target_class, true, predicted):\n",
    "    if len(true) != len(predicted):\n",
    "        raise ValueError('Sequences are of different lengths.')\n",
    "    evl = pd.DataFrame(list(zip(true, predicted)), columns=['True', 'Predicted'])\n",
    "    tp = len(evl[(evl['Predicted'] == target_class) & (evl['True'] == target_class)])\n",
    "    fp = len(evl[(evl['Predicted'] == target_class) & (evl['True'] != target_class)])\n",
    "    fn = len(evl[(evl['Predicted'] != target_class) & (evl['True'] == target_class)])\n",
    "    prec = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    fscore = (2 * prec * recall) / (prec + recall)\n",
    "    return tp, fp, fn, prec, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gut: (28108, 2475, 8308, 0.919072687440735, 0.7718585237258347, 0.8390572993626769)\n",
      "schlecht: (5342, 8308, 2475, 0.3913553113553114, 0.6833823717538697, 0.4976941351842363)\n"
     ]
    }
   ],
   "source": [
    "print('gut:', evaluate('gut', test['Class'], pred))\n",
    "print('schlecht:', evaluate('schlecht', test['Class'], pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
